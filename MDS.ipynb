{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Multi-document summarization","metadata":{}},{"cell_type":"code","source":"pip install transformers==4.18.0","metadata":{"execution":{"iopub.status.busy":"2022-08-17T13:27:32.993480Z","iopub.execute_input":"2022-08-17T13:27:32.994386Z","iopub.status.idle":"2022-08-17T13:27:42.515152Z","shell.execute_reply.started":"2022-08-17T13:27:32.994322Z","shell.execute_reply":"2022-08-17T13:27:42.513709Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport torch\nDEVICE = 0 if torch.cuda.is_available() else -1","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:53:16.780731Z","iopub.execute_input":"2022-08-17T14:53:16.781428Z","iopub.status.idle":"2022-08-17T14:53:16.788415Z","shell.execute_reply.started":"2022-08-17T14:53:16.781389Z","shell.execute_reply":"2022-08-17T14:53:16.787310Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"with open('../input/ztm-topics/ztm_with_topics_50_sentence-transformers_allenai-specter_topic_index.json') as f:\n    index = json.loads(f.read())","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:10:41.426716Z","iopub.execute_input":"2022-08-17T15:10:41.427894Z","iopub.status.idle":"2022-08-17T15:10:41.467253Z","shell.execute_reply.started":"2022-08-17T15:10:41.427840Z","shell.execute_reply":"2022-08-17T15:10:41.466311Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(index['documents'])","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:10:41.820596Z","iopub.execute_input":"2022-08-17T15:10:41.821794Z","iopub.status.idle":"2022-08-17T15:10:41.830221Z","shell.execute_reply.started":"2022-08-17T15:10:41.821733Z","shell.execute_reply":"2022-08-17T15:10:41.828841Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:10:42.175453Z","iopub.execute_input":"2022-08-17T15:10:42.176178Z","iopub.status.idle":"2022-08-17T15:10:42.191403Z","shell.execute_reply.started":"2022-08-17T15:10:42.176140Z","shell.execute_reply":"2022-08-17T15:10:42.190379Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"df.groupby('topic_number').count().sort_values('doi', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:11:26.430380Z","iopub.execute_input":"2022-08-17T16:11:26.430791Z","iopub.status.idle":"2022-08-17T16:11:26.451190Z","shell.execute_reply.started":"2022-08-17T16:11:26.430757Z","shell.execute_reply":"2022-08-17T16:11:26.450038Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topics = df.topic_number.unique()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:13:09.222820Z","iopub.execute_input":"2022-08-17T15:13:09.223809Z","iopub.status.idle":"2022-08-17T15:13:09.229523Z","shell.execute_reply.started":"2022-08-17T15:13:09.223757Z","shell.execute_reply":"2022-08-17T15:13:09.227961Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"len(topics)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:10:57.144278Z","iopub.execute_input":"2022-08-17T16:10:57.144735Z","iopub.status.idle":"2022-08-17T16:10:57.153168Z","shell.execute_reply.started":"2022-08-17T16:10:57.144695Z","shell.execute_reply":"2022-08-17T16:10:57.151714Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for topic in topics:\n    print(topic, df[df['topic_number'] == topic].iloc[0]['keywords'])","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:13:14.569848Z","iopub.execute_input":"2022-08-17T15:13:14.570409Z","iopub.status.idle":"2022-08-17T15:13:14.615051Z","shell.execute_reply.started":"2022-08-17T15:13:14.570359Z","shell.execute_reply":"2022-08-17T15:13:14.613718Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def process_document(documents, tokenizer, docsep_token_id, pad_token_id, device=DEVICE):\n    input_ids_all=[]\n    for data in documents:\n        all_docs = data.split(\"|||||\")[:-1]\n        for i, doc in enumerate(all_docs):\n            doc = doc.replace(\"\\n\", \" \")\n            doc = \" \".join(doc.split())\n            all_docs[i] = doc\n        \n        #### concat with global attention on doc-sep\n        input_ids = []\n        for doc in all_docs:\n            input_ids.extend(\n                tokenizer.encode(\n                    doc,\n                    truncation=True,\n                    max_length=4096 // len(all_docs),\n                )[1:-1]\n            )\n            input_ids.append(docsep_token_id)\n        input_ids = (\n            [tokenizer.bos_token_id]\n            + input_ids\n            + [tokenizer.eos_token_id]\n        )\n        input_ids_all.append(torch.tensor(input_ids))\n    input_ids = torch.nn.utils.rnn.pad_sequence(\n        input_ids_all, batch_first=True, padding_value=pad_token_id\n    )\n    return input_ids\n\n\ndef batch_process(batch, model, tokenizer, docsep_token_id, pad_token_id, device=DEVICE):\n    input_ids=process_document(batch['document'], tokenizer, docsep_token_id, pad_token_id)\n    # get the input ids and attention masks together\n    global_attention_mask = torch.zeros_like(input_ids).to(device)\n    input_ids = input_ids.to(device)\n    # put global attention on <s> token\n\n    global_attention_mask[:, 0] = 1\n    global_attention_mask[input_ids == docsep_token_id] = 1\n    generated_ids = model.generate(\n        input_ids=input_ids,\n        global_attention_mask=global_attention_mask,\n        use_cache=True,\n        max_length=1024,\n        num_beams=5,\n    )\n    generated_str = tokenizer.batch_decode(\n            generated_ids.tolist(), skip_special_tokens=True\n        )\n    result={}\n    result['generated_summaries'] = generated_str\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:05:28.702513Z","iopub.execute_input":"2022-08-17T15:05:28.703025Z","iopub.status.idle":"2022-08-17T15:05:28.714361Z","shell.execute_reply.started":"2022-08-17T15:05:28.702987Z","shell.execute_reply":"2022-08-17T15:05:28.713041Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline, AutoModel, AutoTokenizer, LEDForConditionalGeneration\n\n\nmds_models = [\n    {\"model\": \"allenai/led-base-16384-ms2\", \"type\": \"multi-document\", \"tokenizer\": None },\n    {\"model\": \"allenai/PRIMERA-multixscience\", \"type\": \"multi-document\", \"tokenizer\": None },\n    {\"model\": \"allenai/led-base-16384-multi_lexsum-source-tiny\", \"type\": \"multi-document\", \"tokenizer\": None },\n    {\"model\": \"allenai/led-base-16384-multi_lexsum-source-long\", \"type\": \"multi-document\", \"tokenizer\": None },\n]\n\ntopic_summaries = []\nfor model in mds_models:\n    tok = AutoTokenizer.from_pretrained(model['model'])\n    mdl = LEDForConditionalGeneration.from_pretrained(model['model'])\n    mdl.to(DEVICE)\n    mdl.gradient_checkpointing_enable()\n    pad_token_id = tok.pad_token_id\n    docsep_token_id = tok.convert_tokens_to_ids(\"<doc-sep>\")\n    for topic in topics:\n        cluster = df[df['topic_number'] == topic ]['text']\n        out = batch_process({ 'document': [\"|||||\".join([sent for sent in cluster])]}, mdl, tok, docsep_token_id, pad_token_id)\n        \n        topic_summaries.append({\n            \"topic_number\": topic,\n            \"topic_keywords\": df[df['topic_number'] == topic ]['keywords'].iloc[0],\n            \"model\": model['model'],\n            \"summary\": out['generated_summaries'][0]\n        })\n    del mdl\n    del tok\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:33:28.740100Z","iopub.execute_input":"2022-08-17T16:33:28.741045Z","iopub.status.idle":"2022-08-17T16:44:53.880697Z","shell.execute_reply.started":"2022-08-17T16:33:28.741001Z","shell.execute_reply":"2022-08-17T16:44:53.879519Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel, T5ForConditionalGeneration\n\n\nmodels = [\n    {\"model\": \"BeIR/query-gen-msmarco-t5-large-v1\", \"type\": \"multi-document\", \"tokenizer\": None },\n]\n    \ntopic_queries = []\nfor model in models:\n    tokenizer = AutoTokenizer.from_pretrained(model['model'])\n    mdel = T5ForConditionalGeneration.from_pretrained(model['model'])\n    mdel.to(DEVICE)\n    \n    for topic in topics:\n        cluster = df[df['topic_number'] == topic ]['text']\n        para = \"\".join([sent for sent in cluster])\n        input_ids = tokenizer.encode(para, return_tensors='pt')\n        input_ids = input_ids.to(DEVICE)\n        outputs = mdel.generate(\n            input_ids=input_ids,\n            max_length=256,\n            do_sample=True,\n            top_p=0.95,\n            num_return_sequences=3)\n\n        queries = []\n        for i in range(len(outputs)):\n            query = tokenizer.decode(outputs[i], skip_special_tokens=True)\n            queries.append(query)\n            \n        topic_queries.append({\n            \"topic_number\": topic,\n            \"topic_keywords\": df[df['topic_number'] == topic ]['keywords'].iloc[0],\n            \"model\": model['model'],\n            \"questions\": queries\n        })\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:47:04.475629Z","iopub.execute_input":"2022-08-17T16:47:04.476220Z","iopub.status.idle":"2022-08-17T16:48:02.290276Z","shell.execute_reply.started":"2022-08-17T16:47:04.476182Z","shell.execute_reply":"2022-08-17T16:48:02.289101Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"df_queries = pd.DataFrame(topic_queries)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:48:26.245087Z","iopub.execute_input":"2022-08-17T16:48:26.245572Z","iopub.status.idle":"2022-08-17T16:48:26.255020Z","shell.execute_reply.started":"2022-08-17T16:48:26.245537Z","shell.execute_reply":"2022-08-17T16:48:26.253884Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"df_summaries = pd.DataFrame(topic_summaries)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:48:26.942262Z","iopub.execute_input":"2022-08-17T16:48:26.945751Z","iopub.status.idle":"2022-08-17T16:48:26.958508Z","shell.execute_reply.started":"2022-08-17T16:48:26.945694Z","shell.execute_reply":"2022-08-17T16:48:26.956957Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"top_topics = df.groupby('topic_number').count().sort_values('doi', ascending=False)[[ 'doi']].rename(columns={'doi': 'citations'})\ntop_topics.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:50:25.328015Z","iopub.execute_input":"2022-08-17T16:50:25.328442Z","iopub.status.idle":"2022-08-17T16:50:25.345400Z","shell.execute_reply.started":"2022-08-17T16:50:25.328408Z","shell.execute_reply":"2022-08-17T16:50:25.344274Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"df_summaries.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:53:09.476826Z","iopub.execute_input":"2022-08-17T16:53:09.477378Z","iopub.status.idle":"2022-08-17T16:53:09.507098Z","shell.execute_reply.started":"2022-08-17T16:53:09.477329Z","shell.execute_reply":"2022-08-17T16:53:09.505913Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"for topic in top_topics.head(5).reset_index().topic_number.unique():\n    print(f\"Topic {topic}: {df_summaries[df_summaries['topic_number'] == topic].iloc[0]['topic_keywords']}\")\n    for i, row in df_summaries[df_summaries['topic_number'] == topic].iterrows():\n        print(row['model'])\n        print(row['summary'])\n        print('\\n')","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:56:14.377593Z","iopub.execute_input":"2022-08-17T16:56:14.378716Z","iopub.status.idle":"2022-08-17T16:56:14.395207Z","shell.execute_reply.started":"2022-08-17T16:56:14.378639Z","shell.execute_reply":"2022-08-17T16:56:14.393971Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"\nfor topic in top_topics.head(5).reset_index().topic_number.unique():\n    print(f\"Topic {topic}: {df_summaries[df_summaries['topic_number'] == topic].iloc[0]['topic_keywords']}\")\n    for i, row in df_queries[df_queries['topic_number'] == topic].iterrows():\n        for question in row['questions']:\n            print(question + '?')\n        print('\\n') ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T16:56:51.781024Z","iopub.execute_input":"2022-08-17T16:56:51.781523Z","iopub.status.idle":"2022-08-17T16:56:51.803644Z","shell.execute_reply.started":"2022-08-17T16:56:51.781479Z","shell.execute_reply":"2022-08-17T16:56:51.802482Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}